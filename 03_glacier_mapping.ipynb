{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    .dothis{\n",
       "    font-weight: bold;\n",
       "    color: #ff7f0e;\n",
       "    font-size:large\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    .dothis{\n",
    "    font-weight: bold;\n",
    "    color: #ff7f0e;\n",
    "    font-size:large\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier mapping by means of band math\n",
    "\n",
    "*****\n",
    "\n",
    "This notebook demonstrates how we can use Python to do the same glacier mapping that we earlier carried out in QGIS.\n",
    "\n",
    "There are several points at which you will need to modify a line of code. These are identified by <span class='dothis'>bold orange text</span>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "We start with a few preparation such as reading all the packages we use in the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pystac_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxr\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpystac_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m \n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pystac_client'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import dask.distributed\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pystac_client import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sdc_utilities import get_alias_band, load_product_ts\n",
    "\n",
    "# silence warning (not recommended during development)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Change the size of the figures displayed in the notebooks: units are inches, order is (width, height).\n",
    "plt.rcParams['figure.figsize'] = (16,8)  \n",
    "\n",
    "# Initiate Dask Env\n",
    "client = dask.distributed.Client()\n",
    "# display(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next cell contains the dataset configuration information, which we have already made for you using the [config_tool-SwissDC](config_tool-SwissDC.ipynb) notebook. This ensures that you will have data well suited to map glacier extent.**\n",
    "\n",
    "**To make this notebook run you will need to use anyone of Landsat or Sentinel 2 products with the red green and blue bands, as well as at least one swir band.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "product = 'landsat_ot_c2_l2'\n",
    "measurements = ['QA_PIXEL', 'blue', 'green', 'red', 'nir', 'swir_1', 'swir_2']\n",
    "get_alias_band(product, measurements, measurements_file='measurements_SwissDC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "catalog = Client.open(\"https://explorer.swissdatacube.org/stac\")\n",
    "\n",
    "product = 'landsat_ot_c2_l2'\n",
    "\n",
    "# you can use either specify the real measurement names or the aliases (https://explorer.swissdatacube.org/products/landsat_ot_c2_l2)\n",
    "aliases = ['QA_PIXEL', 'blue', 'green', 'red', 'nir', 'swir_1', 'swir_2']\n",
    "measurements, aliases = get_alias_band(product,measurements, measurements_file=\"measurements_SwissDC.csv\")\n",
    "\n",
    "longitude = (7.73228, 7.957461)\n",
    "latitude = (45.877007, 46.022142)\n",
    "crs = 'epsg:4326'\n",
    "\n",
    "time = ('2016-08-01', '2016-09-30')\n",
    "# the following date formats are also valid:\n",
    "# time = ('2000-01-01', '2001-12-31')\n",
    "# time=('2000-01', '2001-12')\n",
    "# time=('2000', '2001')\n",
    "\n",
    "output_crs = 'epsg:2056'\n",
    "resolution = -30.0, 30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "****\n",
    "\n",
    "__In the following we are using `load_product_ts()` to load the data. There is also a function to mask out cloud obscured values using the pixel quality bands (`QA_PIXEL` in Landsat and `SLC` in Sentinel). We see later more on this.__\n",
    "\n",
    "Here we are using `load_product_ts` because the cloud masking does not work in the mountains where snow and ice get confused with clouds. \n",
    "\n",
    "**However, this means we now have to look at the scenes and manually decide which ones are cloud free.**\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_in = load_product_ts(catalog = catalog,\n",
    "                          product = product,\n",
    "                          time = time,\n",
    "                          longitude = longitude,\n",
    "                          latitude = latitude,\n",
    "                          measurements = measurements,\n",
    "                          output_crs = output_crs,\n",
    "                          resolution = resolution,\n",
    "                          rename = True,               # This will overwrite the band names with the aliases names ...\n",
    "                          alias_names = aliases,        # ... that need to be specified here in that case.\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the xarray.Dataset to get an overview of the different scenes along the time axis\n",
    "dataset_in.blue.plot(col='time', col_wrap=5, cmap='Greys', vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a cloud free scene\n",
    "\n",
    "As mentioned before, we have used the `dc.load()` function which does not mask cloud covered areas. \n",
    "\n",
    "<span class='dothis'>We now have to plot all time steps again and then visually define which of the scenes is cloud free.</span>\n",
    "\n",
    "This is best done by visualizing composites, either true color or false color. In the following we first visualize the data in true color, followed by two examples of popular false color visualization for Landsat data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot composites in True color (red, green, blue)\n",
    "# robust=True guesses the minimum and maximum values for each image.\n",
    "dataset_in[['red','green','blue']].to_array().plot.imshow(col='time',col_wrap=5, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot composites in False color (nir, red, green)\n",
    "dataset_in[['nir','red', 'green']].to_array().plot.imshow(col='time',col_wrap=5, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot composites in another false color combination, this time (swir1, nir, red) which is well suited to see ice and snow\n",
    "dataset_in[['swir_1','nir', 'red']].to_array().plot.imshow(col='time',col_wrap=5, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of which visualization we work with, we see that from the seven scenes, only one appears cloud free: **2016-08-25T10:10:52**. We continue working only with that scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select the image we are interested in and save it to a new variable.\n",
    "# To do this we provide the date of the image we selected above \n",
    "# The squeeze() command removes the time dimension from the DataArray, so you are left with two dimensions: latitude and longitude.\n",
    "mosaic = dataset_in.sel(time='2016-08-25').squeeze()\n",
    "mosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mosaic_plot'> </a>\n",
    "Plot mosaic the default way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To do this we need to provide the list of bands we are interested in.\n",
    "mosaic[['red','green','blue']].to_array().plot.imshow(robust=True)\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now export to a GeoTIFF file.\n",
    "mosaic[['red','green','blue']].astype('int32').rio.to_raster(\"glaciers.tif\", driver=\"COG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Band math for glacier detection\n",
    "\n",
    "*****\n",
    "\n",
    "We now detect glacier surfaces using the band math: *G = Red / Swir*\n",
    "\n",
    "Thereby a threshold needs to be defined to distinguish glaciers from non-glacierized terrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = mosaic.red / mosaic.swir_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can (or can not) recognize the result. Maybe we can improve the extent of the automatically generated scale. \n",
    "\n",
    "It seems that inside the dataset there might be one or a few pixels with extreme values (either artifacts or values indicating invalid pixels). These outliers result in the automated choice of the data range. \n",
    "\n",
    "The easy way to visualize the data while ignoring the outliers is to pass the parameter robust=True. This will use the 2nd and 98th percentiles of the data to compute the color limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note how the color palette has changed.** This is simply because the `DataArray.plot()` function we are using tries to automatically define the optimal colormap. \n",
    "\n",
    "We can suppress this behaviour by specifying a colormap from https://matplotlib.org/stable/gallery/color/colormap_reference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot(robust=True, cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to plot the data as a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there would be an outlier, this would either throw an error message, telling us that the data range reaches infinity. Other problems could be (if you load the dataset with the argument `scale_offset` that some division causes artifacts with e.g. negative values. In the text output (directly below the executed cell), you can see the bin breaks. If you have negative values they will show up there.\n",
    "\n",
    "In case you will encounter the infinity error or strange automatic bin breaks, there is a solution below. \n",
    "\n",
    "- First, remove all values that have the value \"infinte\" and then try to plot the histogram again.\n",
    "- Keep only values bigger `x_low` (`x_low` would be your lower threshold value)\n",
    "- Keep only values small `x_hig` (`x_hig` would be your upper threshold value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = G.where(np.isfinite(G))  # Set all values that are not finite to NaN (Not a Number)\n",
    "G = G.where((G>=0) & (G<=100),np.nan)  # Set all values that are not finite to NaN (Not a Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works but there are situation where we might want to have more control on how exactly a histogram is plotted. For example: \n",
    "\n",
    "* Let's change the range of values shown in the histogram of G\n",
    "* Let's increase the number of bins in the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot.hist(bins=40, range=(-50, 50))  # We added the \"bin\" keyword that allows specifying the number of bins to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not perfect yet, e.g. there is no need to visualize all the absence of data on the left-hand side. <span class='dothis'>Adjust the parameters in the plotting command above so you achieve an optimal visualization.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the threshold value for glacier mapping\n",
    "\n",
    "Now to the actual glacier mapping. <span class='dothis'>As we did in QGIS, we will define a threshold to distinguish between glaciers (where <i>G > threshold</i>) and non-glacierized terrain (<i>G < threshold</i>).</span>\n",
    "\n",
    "We can directly test whether the threshold is appropriate by plotting the scene, but this time telling the program to use discrete colors for all values that are within intervals that we define with the `levels` keyword. Note that we need to define at least two values for `levels`. We simply chose the first one very low, outside the range of data values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set the threshold - CHANGE THIS TO VARY THE THRESHOLD!\n",
    "threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the \"levels\" keyword which allows specifying the boundaries between discrete classes for plotting. \n",
    "G.plot(levels=[0, threshold])  # Here the resulting classes are (1) smaller -100, (2) between -100 and \"threshold\", (3) larger than \"Trheshold\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot now shows all grid cell with values between -100 and \"threshold\" in one colour, all grid cells with values > threshold in another colour.\n",
    "\n",
    "This is excellent, **but has the disadvantage that we have no comparison with the original scene, to be able to assess how accurately our chosen threshold distinguishes glaciers from non-glacierized terrain.**\n",
    "\n",
    "We thus go more fancy and **plot the above threshold map *and* a false color composite of the original scene on top of each other.** We do this by simply calling the `plot()` function twice, the two graphics will then be plotted into the same figure. Furthermore, we use the `alpha` parameter to define how transparent the threshold map should be (`alpha = 0` fully transparent, `alpha = 1` fully opaque)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot(levels=[0, threshold], alpha=0.3)\n",
    "mosaic[['red','green','blue']].to_array().plot.imshow(robust=True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these tools at hand, <span class='dothis'>vary the threshold to find an optimal treshold value.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistics\n",
    "\n",
    "**Now to some very basic statistics: How many percent of the chosen satellite image are glacier covered?**\n",
    "\n",
    "We calculate this by taking the number of glacierized grid cells `(G.where(G > threshold)).count()` and divide them by the total number of grid cells `G.count()`. The result is again a xr.DataArray which contains just the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * (G.where(G > threshold)).count() / G.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100 * (G.where(G > threshold)).count() / G.count()).values     # adding .values to an xarray returns just the values of the array inside it --> 41.9 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the results\n",
    "\n",
    "After we found an optimal threshold value, let's now create an array where all glacier grid cells have the value 1, and all non-glacierized cells have the value 0.\n",
    "\n",
    "We do this by using the `xr.where()` function. Its syntax is `xr.where(condition, value to use where condition is True, value to use where condition is False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier = xr.where(G > threshold, 1, 0)\n",
    "glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier.plot()  # plt it once again to see whether the result is what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class='dothis'>If everything looks fine, then it is now time to export our glacier map. We do this by using the function `rio.to_raster()`.</span>\n",
    "\n",
    "Note that our xr.DataArray named *glacier* is of the data type `int32` (= 32 bit integer). The export function cannot handle this data type. Thus we convert *glacier* to data type `int16` (16 bit integer) during export by using `glacier.astype('int16')`.\n",
    "\n",
    "This makes a 'GeoTIFF' file which can be loaded into software like QGIS or ArcGIS. Note that GeoTIFFs are not properly understood by programs like Photos or Photoshop, so they will look quite strange if they open at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier.astype('int16').rio.to_raster(\"glacier_map.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
